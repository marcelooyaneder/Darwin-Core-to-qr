{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCCIÓN\n",
    "Este software, desarrollado completamente en python, tiene la funcionalidad de leer una base de datos basada en Darwin Core (DwC) y poder realizar un análisis de esta, a continuación se da una lista de las funciones implementadas que se tiene.  Por el momento para mostrar tus datos es necesario que tu proyecto este alojado en GitHub.\n",
    "\n",
    " - Leer bases de datos basadas en DwC en formato .xlsx o .csv.\n",
    " - Eliminar columnas vacias que poseas en tu base de datos.\n",
    " - Identificar columnas que no pertenezcan a DwC.\n",
    " - Obtener códigos Qr que dirigan a un link con la información de tu base de datos. \n",
    " - Poder filtrar tus datos para poder realizar cambios u obtener solo una lista de estos.\n",
    "\n",
    "> Recomendamos utilizar la versión de jupyter notebook, si es que no estas familiarizado con python.\\\n",
    "Tambien existe la versión pura del código en python, es exactamente igual a la de jupyter, salvo algunas excepciones para mejor visualización de los datos en jupyter.\n",
    "\n",
    "# EJECUCIÓN DEL PROGRAMA\n",
    "\n",
    "## Instalación de Software y paquetes\n",
    "Para el correcto funcionamiento del software es necesario tener lo siguiente instalado en tu pc.\n",
    "\n",
    " - python 3.7, lo puedes descargar en el siguiente link https://www.python.org/downloads/release/python-370/\n",
    "   - Al instalar python asegurate de tener marcada la casilla \"Add python 3.7 to PATH\" \n",
    "![](https://lh3.googleusercontent.com/nkCqWV88bAT5wzDic6_IQDG6S0fVMuJjTRo5Kqc8A914MsyOd0CRBHL871WsEeQ6hNl6oz5SPy5Q \"python PATH\")\n",
    " - package manager pip (incluido en la instalación previa).\n",
    " - GitHub Desktop.\n",
    " - Descargar este repositorio.\n",
    "\n",
    "Luego de la instalación de lo anterior, la acción siguiente si deseas ejecutar el software es escribir lo siguiente en la terminal (cmd o powershell en windows). \n",
    "\n",
    "    pip3 install jupyter\n",
    "\n",
    "**El resto de los paquetes se instalará automáticamente cuando ejecutes el software.**\n",
    "\n",
    "## Primeros pasos\n",
    " - Primero que todo es necesario darle un formato específico a el archivo a leer por el software (de preferencia excel), y el formato consta de lo siguiente: \n",
    "   - En la primera fila debe ir el nombre de las columnas de DwC, no importa el orden de estas, y debajo de estas debe ir la información, a continuación se muestra una imagen a modo de ejemplo.\n",
    "   - Importante decir que si existe el valor \"class\" en tu base de datos, este debe ser cambiado por el valor \"Class\".\n",
    "\n",
    "![](https://lh3.googleusercontent.com/FgeRnw0GgiSvFHWSpznlj61G53NOGtgadUZqFHZ7v4jZIJ1PrTuoPArOH0eMhVpMMWPqh1wlhb0a \"Format\")\n",
    "\n",
    " - Lo siguiente es alojar todos los archivos que necesitas en tu repositorio GitHub, adjuntamos un video en caso de que no conozcas el proceso.\n",
    " \n",
    "[![](http://img.youtube.com/vi/gjMEehpSTNk/0.jpg)](http://www.youtube.com/watch?v=gjMEehpSTNk \"\")\n",
    "\n",
    " - Abrir GitHub Desktop y sincronizar el nuevo repositorio creado a tu pc. (recomendamos ver el siguiente video...)\n",
    "\n",
    "[![](http://img.youtube.com/vi/IW28zJc7BN0/0.jpg)](http://www.youtube.com/watch?v=IW28zJc7BN0 \"\")\n",
    "\n",
    " - Copiar los contenidos descargados de este repositorio a tu **nuevo repositorio**.\n",
    " - Luego dirigirse a la carpeta documents y abrir el archivo \"dynamiclinks_user_info.csv\" y llenar este con los datos requeridos, donde:\n",
    "    - GitHub_username: corresponde al nombre de usuario de tu cuenta GitHub.\n",
    "    - Repository_name: corresponde al nombre del repositorio que mantiene tu proyecto.\n",
    "    - api_key y sub_domain: son extraídos de la web de google Firebase dinamic links, contactarse a mi correo para conseguir una o indicarte como (marcelo.oyaneder.l@gmail.com)\n",
    "\n",
    " - Dirigirte a la carpeta en que estén los archivos descargados del repositorio, abrir nuevamente una terminal (esta debe tener la dirección de esta carpeta) y ejecutar lo siguiente:\n",
    "\n",
    "    jupyter notebook\n",
    "\n",
    "   - Y tendrás una ventana en tu navegador de la siguiente forma, aqui debes abrir el archivo \"main.ipynb\".\n",
    "\n",
    "![jupyter notebook init](https://lh3.googleusercontent.com/HLbKzsT1i5E8H33-IZ3EwOt1dtB55Jl6-nLQ03JcY80AsMlrUOJRLSsZz9CJNVPIYZuhNLpgSHvu \"jupyter screenshot\")\n",
    " \n",
    "- Por último es ejecutar el código, para esto en la ventana de jupyter notebook ir a la pestaña.\n",
    "\n",
    "    kernel > Restart & Run all\n",
    "\n",
    "- Seguir las indicaciones del software.\n",
    "- Abrir GitHub Desktop y actualizar tus datos.\n",
    "\n",
    "# CRÉDITOS\n",
    "Software desarrllado en el _laboratorio de biología de plantas_ ubicado en el campus Antumapu perteneciente a la Universidad de Chile.\n",
    " - Autores: \n",
    "   - Marcelo Oyaneder Labarca.\n",
    "   - Paulette Naulin Gysling.  \n",
    " - Contacto:\n",
    "   - marcelo.oyaneder.l@gmail.com\n",
    "   - pnaulin@uchile.cl\n",
    "\n",
    "![](https://lh3.googleusercontent.com/kwADztygurIvFqRkhgTwMKz5QakvqDIFK8NO_8f5Oxhik9G8hYz9xfO3mPbBhJUftU5oLu4NTIfl)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package installation & configs of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\" # CRÉDITOS\n",
    "Software desarrllado en el laboratorio de biología de plantas ubicado en el campus Antumapu perteneciente a la Universidad de Chile.\n",
    " - Autores: \n",
    "   - Paulette Naulin Gysling.  \n",
    "   - Marcelo Oyaneder Labarca.\n",
    " - Contacto:\n",
    "   - marcelo.oyaneder.l@gmail.com\n",
    "   - pnaulin@uchile.cl \"\"\"\n",
    "\n",
    "#package imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import errno\n",
    "import pyqrcode\n",
    "from pathlib import Path\n",
    "import filecmp\n",
    "import shutil\n",
    "from python_firebase_url_shortener.url_shortener import UrlShortener\n",
    "import time\n",
    "import sys\n",
    "import easygui as eg\n",
    "import numpy \n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "#autoidenficar el separator en csv ; o ,\n",
    "class file_manager:\n",
    "    def file_opener(self):\n",
    "        #search if a csv file has been created previusly \n",
    "        try:\n",
    "            data=pd.read_csv('dataframe.csv',header=0,sep=';') #ver como variar de ; o ,\n",
    "        except:\n",
    "            file_path=eg.fileopenbox(msg='pick the file wish contain your data',title='directory',default='*',filetypes=None,multiple=False)\n",
    "            if file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "                data=pd.read_excel(file_path,sheet_name='Hoja1',header=0)\n",
    "            elif file_path.endswith('.csv'):\n",
    "                data=pd.read_csv(file_path,header=0,sep=';') #ver como variar de ; o ,\n",
    "        columns_df=data.columns.tolist()\n",
    "        msg='select a column to be the index of the dataframe'\n",
    "        title='select index'       \n",
    "        indexo=eg.choicebox(msg,title,columns_df)\n",
    "        data=data.set_index(indexo, drop = False)\n",
    "        og_data=data.copy()\n",
    "        og_columns_df=og_data.columns.tolist()\n",
    "        columns_dwc=pd.read_csv('documents\\dwc_terms\\simple_dwc_horizontal.csv',header=0,sep=';').columns.tolist() #ver como variar de ; o , \n",
    "        columns_difference=list(set(columns_df)-set(columns_dwc))\n",
    "        if not columns_difference:\n",
    "            pass\n",
    "        else:\n",
    "            msg='the followings columns do not belong to DwC, select the ones you wish to delete'\n",
    "            title='select to delete'       \n",
    "            choicebox=eg.multchoicebox(msg,title,columns_difference)\n",
    "            try:\n",
    "                for label in choicebox:\n",
    "                    data.drop(label,axis=1,inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "        empty_columns_drop_answer=eg.ynbox(msg='Do you wish to delete the empty columns?...',title='Drop empty columns') #a way to drop fully empty columns\n",
    "        if empty_columns_drop_answer==True:\n",
    "            data.dropna(axis=1, how='all',inplace=True)\n",
    "            og_data.dropna(axis=1, how='all',inplace=True)\n",
    "            og_data.to_csv('online_dataframe.csv',sep=',')\n",
    "        else:\n",
    "            pass\n",
    "        return og_data,data,indexo,og_columns_df\n",
    "    \n",
    "    def file_creation(self):\n",
    "        Record_level=pd.read_csv('documents\\dwc_terms\\Record_level.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Ocurrence=pd.read_csv('documents\\dwc_terms\\Ocurrence.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Organism=pd.read_csv('documents\\dwc_terms\\organism.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Material_sample=pd.read_csv('documents\\dwc_terms\\MaterialSample.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Event=pd.read_csv('documents\\dwc_terms\\event.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Location=pd.read_csv('documents\\dwc_terms\\location.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Geological_Context=pd.read_csv('documents\\dwc_terms\\GeologicalContext.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Identification=pd.read_csv('documents\\dwc_terms\\identification.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        Taxon=pd.read_csv('documents\\dwc_terms\\Taxon.csv',header=0,sep=';',encoding = 'unicode_escape')\n",
    "        columns_dwc=[Record_level,Ocurrence,Organism,Material_sample,Event,Location,Geological_Context,Identification,Taxon]\n",
    "        dwc_columns=[]\n",
    "        for dataframe in columns_dwc:\n",
    "            level_list=[]\n",
    "            for rows in dataframe.itertuples():\n",
    "                    # Create list for the current row \n",
    "                    my_list =f'{rows.standardFieldName}-{rows.verbatimFieldName}-{rows.uri}'   \n",
    "                    # append the list to the final list \n",
    "                    level_list.append(my_list)\n",
    "            msg='select the terms for your custom dwc dataframe'\n",
    "            title='select terms'       \n",
    "            choicebox=eg.multchoicebox(msg,title,level_list)\n",
    "            try:\n",
    "                for elements in choicebox:\n",
    "                    try:\n",
    "                        indice=level_list.index(elements)\n",
    "                        value=dataframe['standardFieldName'][indice]\n",
    "                        dwc_columns.append(value)\n",
    "                    except:\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "        dataframe=pd.DataFrame(columns=dwc_columns)\n",
    "        return dataframe\n",
    "\n",
    "class subject:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "\n",
    "    def datafiltering(self,data):\n",
    "        columns_df=data.columns.tolist()\n",
    "        msg='select a value to query'\n",
    "        title='select'\n",
    "        choicebox=eg.choicebox(msg,title,columns_df)\n",
    "        querys=data[choicebox].unique()\n",
    "        query_choicebox=eg.choicebox(msg,title,querys)\n",
    "        data.query(f\"{choicebox}=='{query_choicebox}'\",inplace=True) \n",
    "        return data\n",
    "    \n",
    "    def datafiltering_predef(self,data,column):\n",
    "        msg='select a value to query'\n",
    "        title='select'\n",
    "        querys=data[column].unique()\n",
    "        query_choicebox=eg.choicebox(msg,title,querys)\n",
    "        data.query(f\"{column}=='{query_choicebox}'\",inplace=True) \n",
    "        return data\n",
    "\n",
    "    def change_values(self,data,og_data,subjects): \n",
    "        IDs_for_change=eg.multchoicebox(msg='Select the subject(s) for a change: ',title='Select...',choices=subjects)    \n",
    "        columns=data.columns.tolist()\n",
    "        new_value_change=True\n",
    "        while new_value_change==True:\n",
    "            values_to_change=eg.choicebox(msg='The following values are available for change: ',title='Select...',choices=columns)\n",
    "            set_value=eg.enterbox(msg=f'Enter a new value for {values_to_change}: ',title='New value...')\n",
    "            for values in IDs_for_change:\n",
    "                try:\n",
    "                    data.at[values,values_to_change]=set_value\n",
    "                    data.at[values,'acceptedNameUsage']= '{0} {1} {2}'.format(data.at[values,'genus'],data.at[values,'specificEpithet'],data.at[values,'nameAcordingTo'])\n",
    "                    og_data.at[values,values_to_change]=set_value\n",
    "                    og_data.at[values,'acceptedNameUsage']= '{0} {1} {2}'.format(data.at[values,'genus'],data.at[values,'specificEpithet'],data.at[values,'nameAcordingTo'])\n",
    "                except:\n",
    "                    print('The changes can not be made')\n",
    "                    pass\n",
    "            new_value_change=eg.ynbox(msg='Do you want to change another values in this subjects?',title='Value change')\n",
    "        return data\n",
    "        \n",
    "    def add_values(self,data):\n",
    "        msg = \"Enter information about the new subject\"\n",
    "        title = \"New subject entry \"\n",
    "        last_indexo =data.index[-1]\n",
    "        new = int(last_indexo, 36) + 1\n",
    "        new_id=numpy.base_repr(new, 36)\n",
    "        fieldNames = data.columns.tolist()[1:]\n",
    "        fieldValues = []\n",
    "        fieldValues = eg.multenterbox(msg,title, fieldNames)\n",
    "        fieldValues.insert(0,new_id)\n",
    "        data.loc[fieldValues[0]]=fieldValues\n",
    "        return data\n",
    "\n",
    "    def save_values(self,data): #programar para que tire a csv\n",
    "        path_choice=eg.diropenbox(msg='choose a folder to save a file',title='select a path')\n",
    "        folder_name=eg.enterbox(msg='Enter the filename', title='Filename', default='DataFrame', strip=True, image=None, root=None)\n",
    "        with pd.ExcelWriter(f\"{path_choice}\\{folder_name}.xlsx\") as writer:\n",
    "            data.to_excel(writer, sheet_name='DataFrame')\n",
    "    \n",
    "\n",
    "def comparefiles(ID,info,option): #option 1 for showroom, 0 files \n",
    "    filename1 = f\"temp/{ID}.txt\"\n",
    "    if option==1:\n",
    "        filename2= f\"showroom_files/{ID}.txt\"\n",
    "    elif option==0:\n",
    "        filename2= f\"files/{ID}.txt\"\n",
    "    os.makedirs(os.path.dirname(filename1), exist_ok=True)\n",
    "    with open(filename1,'w') as fil:\n",
    "        fil.write(str(info))\n",
    "    if os.path.isfile(filename2)==True:\n",
    "        if filecmp.cmp(filename1,filename2)==False:\n",
    "            print(f'ive found some changes since the last time, on file... {ID}.txt')\n",
    "            print('changes has been saved')\n",
    "            shutil.move(filename1,filename2)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print(f'a new entry has been found, file... {ID}.txt has been created.')\n",
    "        os.makedirs(os.path.dirname(filename2), exist_ok=True)\n",
    "        with open(filename2,'w') as fil:\n",
    "            fil.write(str(info))\n",
    "    shutil.rmtree('temp/', ignore_errors=False, onerror=None)\n",
    "    return \n",
    "\n",
    "def infowriting(ID,info,option):  #option 1 for showroom, 0 files\n",
    "    try: \n",
    "        if option ==0:\n",
    "            filename = f\"files/{ID}.txt\" \n",
    "        elif option==1:\n",
    "            filename = f\"showroom_files/{ID}.txt\" \n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        with open(filename,'w') as fil:\n",
    "            fil.write(str(info))\n",
    "        print(f'a new entry has been found, file...{ID}.txt has been created.')\n",
    "    except:\n",
    "        print(f'permission to write in {filename} has been denied...')\n",
    "    return \n",
    "\n",
    "def dynamiclinks(longurl):\n",
    "    user_info=pd.read_csv(\"documents\\dynamiclinks_user_info.csv\",header=0,sep=';')\n",
    "    api_key=user_info['api_key'][0] #this need to be created on the firebase webpage\n",
    "    sub_domain=user_info['sub_domain'][0] #this need to be created on firebase webpage\n",
    "    try:\n",
    "        url_shortener = UrlShortener(api_key,sub_domain)\n",
    "        shorturl=url_shortener.get_short_link(longurl)\n",
    "    except:\n",
    "        print('Oops! you have reached the limit of urls')\n",
    "    time.sleep(0.2) #to not break the limits of firebase\n",
    "    return shorturl\n",
    "\n",
    "#crear un Qr para showroom \n",
    "#Crear un Qr para manejo del lab\n",
    "def qr_manager(ID,short_url,option): #option 1 for showroom, 0 files\n",
    "    try:\n",
    "        if option ==0:\n",
    "            filename = f\"qrs/{ID}.png\"\n",
    "        elif option==1:\n",
    "            filename = f\"qrs_showroom/{ID}.png\"\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        quick_response_code= pyqrcode.create(short_url)\n",
    "        with open(filename, 'wb') as f:\n",
    "                quick_response_code.png(f, scale=8,module_color=(0,102,0,255),background=(255, 255, 255, 255))\n",
    "        try:\n",
    "            img = Image.open(filename)\n",
    "            width, height = img.size\n",
    "            logo_size =50\n",
    "            logo = Image.open('documents\\logo.png')\n",
    "            xmin = ymin = int((width / 2) - (logo_size / 2))\n",
    "            xmax = ymax = int((width / 2) + (logo_size / 2))\n",
    "            logo = logo.resize((xmax - xmin, ymax - ymin))\n",
    "            img.paste(logo, (xmin, ymin, xmax, ymax))\n",
    "            img.save(filename)\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        print(f'permission to write in {filename} has been denied...')\n",
    "\n",
    "####################################################################\n",
    "##############################MAIN##################################\n",
    "####################################################################\n",
    "\n",
    "#######################################\n",
    "########FILE MANAGEMENT SECTION########\n",
    "#######################################\n",
    "\n",
    "dataframe=file_manager()\n",
    "file_mng_button=eg.buttonbox(msg='select an option',title='select an option',choices=['Open a file','Create a custom dwc file'])\n",
    "if file_mng_button=='Open a file':\n",
    "    og_data,data,indexo,og_columns_df=dataframe.file_opener() #no considerar para file_creation\n",
    "    IDs=data.index.tolist() #no considerar para file_creation \n",
    "    showroom_option_button=eg.buttonbox(msg='do you wish to create files for a showroom',title='select a option',choices=['Yes','No'])\n",
    "    if showroom_option_button=='Yes':\n",
    "        data_showroom=og_data.copy()\n",
    "        msg='select the columns to keep on your showroom dataframe'\n",
    "        title='select'\n",
    "        choicebox=eg.multchoicebox(msg,title,og_columns_df)\n",
    "        try:\n",
    "            data_showroom=data_showroom[choicebox]\n",
    "        except:\n",
    "            pass\n",
    "    elif showroom_option_button=='No':\n",
    "        pass\n",
    "elif file_mng_button=='Create a custom dwc file':\n",
    "    data=dataframe.file_creation() #no considerar para file_opener\n",
    "    data.to_csv('custom_dwc_frame.csv',sep=';', encoding='utf-8') #considerar para file opener\n",
    "    print ('your file is ready....')\n",
    "    display(data)\n",
    "    exit()\n",
    "\n",
    "display(data)\n",
    "\n",
    "##################################\n",
    "########QUERY DATA SECTION########\n",
    "##################################\n",
    "\n",
    "query_choicebox_options=['Yes...Custom query','Query by: order-family-genus-specificEpithet','Query by: Class-order-family-genus-specificEpithet','No']\n",
    "query_choicebox=eg.choicebox(msg='Do you wish to query your data...',title='Query options',choices=query_choicebox_options)\n",
    "if query_choicebox==query_choicebox_options[0]:\n",
    "    data_for_query=data.copy()\n",
    "    r1=subject(data_for_query)\n",
    "    answer_query_choicebox=True\n",
    "    while answer_query_choicebox==True:\n",
    "        r1.datafiltering(data_for_query)\n",
    "        print(data_for_query)\n",
    "        answer_query_choicebox=eg.ynbox(msg='Do you wish to make a new query?',title='Select an option')\n",
    "    print('Your query has been finished....')\n",
    "    print(data_for_query)\n",
    "elif query_choicebox==query_choicebox_options[1]:\n",
    "    data_for_query=data.copy()\n",
    "    r1=subject(data_for_query)\n",
    "    column_query_predef=['order','family','genus','specificEpithet']\n",
    "    for columns_predef in column_query_predef:\n",
    "        r1.datafiltering_predef(data_for_query,columns_predef)\n",
    "    print('Your query has been finished....')\n",
    "    display(data_for_query)\n",
    "elif query_choicebox==query_choicebox_options[2]:\n",
    "    data_for_query=data.copy()\n",
    "    r1=subject(data_for_query)\n",
    "    column_query_predef=['Class','order','family','genus','specificEpithet']\n",
    "    for columns_predef in column_query_predef:\n",
    "        r1.datafiltering_predef(data_for_query,columns_predef)\n",
    "    print('Your query has been finished....')\n",
    "    display(data_for_query)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if not query_choicebox==query_choicebox_options[3] or query_choicebox==None:\n",
    "    choicebox_for_after_query_options=['export your query to a xlsx file (readable for excel)','make changes on your query and export them to a xlsx file (this changes will be saved on your original file)','show the subjects wich match your query']\n",
    "    choicebox_for_after_query=eg.choicebox(msg='Choose an option for your query...',title='Query options',choices=choicebox_for_after_query_options)\n",
    "    if choicebox_for_after_query==choicebox_for_after_query_options[0]:\n",
    "        #export your query to a xlsx file (readable for excel)\n",
    "        r1.save_values(data_for_query)\n",
    "    elif choicebox_for_after_query==choicebox_for_after_query_options[1]:\n",
    "        #make changes on your query and export them to a xlsx file (this changes will be saved on your original file)\n",
    "        query_subjects=data_for_query[indexo].tolist()\n",
    "        r1.change_values(data,og_data,query_subjects) \n",
    "        r1.save_values(og_data) #for saving original data\n",
    "    elif choicebox_for_after_query==choicebox_for_after_query_options[2]:\n",
    "        #show the subjects wich match your query\n",
    "        query_subjects=data_for_query[indexo].tolist()\n",
    "        for values in query_subjects:\n",
    "            print(values)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Add values \n",
    "#r1.add_values(data)\n",
    "\n",
    "#compare files or create them\n",
    "print('compare/create files...')\n",
    "if os.path.isdir('files')==True:\n",
    "    for id in IDs:\n",
    "        comparefiles(id,data.loc[id],0)\n",
    "else:\n",
    "    for id in IDs:\n",
    "        infowriting(id,data.loc[id],0)\n",
    "\n",
    "if showroom_option_button=='Yes':\n",
    "    if os.path.isdir('showroom_files')==True:\n",
    "        for id in IDs:\n",
    "            comparefiles(id,data_showroom.loc[id],1)\n",
    "    else:\n",
    "        for id in IDs:\n",
    "            infowriting(id,data_showroom.loc[id],1)\n",
    "print ('there is nothing more to do here...')\n",
    "\n",
    "#compare qr files or create them\n",
    "#compare qr files or create them\n",
    "user_info=pd.read_csv(\"documents\\dynamiclinks_user_info.csv\",header=0,sep=';')\n",
    "GitHub_username=user_info['GitHub_username'][0] #this need to be created on the GitHub webpage\n",
    "Repository_name=user_info['Repository_name'][0] #this need to be created on the firebase webpage\n",
    "print('create non existing qrs files...')\n",
    "if os.path.isdir('qrs')==True:\n",
    "    for id in IDs:\n",
    "        print(f'file {id} of file {IDs[-1]}',end='\\r', flush=True)\n",
    "        path=f\"qrs/{id}.png\"\n",
    "        if os.path.isfile(path)==False:\n",
    "            longurl=f'https://raw.githubusercontent.com/{GitHub_username}/{Repository_name}/master/files/{id}.txt'            \n",
    "            shorturl=dynamiclinks(longurl)\n",
    "            qr_manager(id,shorturl,0)\n",
    "        else:\n",
    "            pass\n",
    "else:\n",
    "    for id in IDs:\n",
    "        print(f'file {id} of file {IDs[-1]}',end='\\r', flush=True)\n",
    "        longurl=f'https://raw.githubusercontent.com/{GitHub_username}/{Repository_name}/master/files/{id}.txt'\n",
    "        shorturl=dynamiclinks(longurl)\n",
    "        qr_manager(id,shorturl,0)\n",
    "\n",
    "if showroom_option_button=='Yes':\n",
    "    print('create non existing qrs shorwoom files...')\n",
    "    if os.path.isdir('qrs_showroom')==True:\n",
    "        for id in IDs:\n",
    "            print(f'file {id} of file {IDs[-1]}',end='\\r', flush=True)\n",
    "            path=f\"qrs_showroom/{id}.png\"\n",
    "            if os.path.isfile(path)==False:\n",
    "                longurl=f'https://raw.githubusercontent.com/{GitHub_username}/{Repository_name}/master/showroom_files/{id}.txt'\n",
    "                shorturl=dynamiclinks(longurl)\n",
    "                qr_manager(id,shorturl,1)\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        for id in IDs:\n",
    "            print(f'file {id} of file {IDs[-1]}',end='\\r', flush=True)\n",
    "            longurl=f'https://raw.githubusercontent.com/{GitHub_username}/{Repository_name}/master/showroom_files/{id}.txt'\n",
    "            shorturl=dynamiclinks(longurl)\n",
    "            qr_manager(id,shorturl,1)\n",
    "else:\n",
    "    pass\n",
    "print ('there is nothing more to do here...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data['phylum'].value_counts().plot(kind='bar',title='phylum ',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data['Class'].value_counts().plot(kind='bar',title='class ',figsize=(5,5))                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data['order'].value_counts().plot(kind='bar',title='order ',figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data['family'].value_counts().plot(kind='bar',title='family ',figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data['genus'].value_counts().plot(kind='bar',title='genus ',figsize=(25,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
